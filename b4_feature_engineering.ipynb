{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import is_datetime64_ns_dtype\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \n",
    "    \"\"\" \n",
    "    Iterate through all numeric columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object and not is_datetime64_ns_dtype(df[col]) and not 'category':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int32)  \n",
    "            else:\n",
    "\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_awake = dict(zip(range(1440), np.sin(np.linspace(0, np.pi, 1440) + 0.208 * np.pi) ** 24))\n",
    "signal_onset = dict(zip(range(1440), np.sin(np.linspace(0, np.pi, 1440) + 0.555 * np.pi) ** 24))\n",
    "\n",
    "def feat_eng(df):\n",
    "    \n",
    "    df['series_id'] = df['series_id'].astype('category')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n",
    "    \n",
    "    df.sort_values(['timestamp'], inplace=True)\n",
    "    \n",
    "    df['signal_onset'] = (df.timestamp.dt.hour * 60 + df.timestamp.dt.minute).map(signal_onset).astype(np.float32)\n",
    "    df['signal_awake'] = (df.timestamp.dt.hour * 60 + df.timestamp.dt.minute).map(signal_awake).astype(np.float32)\n",
    "    df[\"anglez_diff\"] = df[\"anglez\"].diff().astype(np.float32)\n",
    "    df[\"anglez_diffabs\"] = abs(df[\"anglez_diff\"]).astype(np.float32)\n",
    "    df[\"anglezabs\"] = abs(df[\"anglez\"]).astype(np.float32)\n",
    "    df['anglez_x_enmo'] = (df['anglez'] * df['enmo']).astype(np.float32)\n",
    "    \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    df['lids'] = np.maximum(0., df['enmo'] - 0.02)\n",
    "    df['lids'] = df['lids'].rolling(f'{120*5}s', center=True, min_periods=1).agg('sum')\n",
    "    df['lids'] = 100 / (df['lids'] + 1)\n",
    "    df['lids'] = df['lids'].rolling(f'{360*5}s', center=True, min_periods=1).agg('mean').astype(np.float32)\n",
    "\n",
    "    for col in ['enmo', 'anglez', 'anglez_x_enmo', 'anglezabs', 'anglez_diff', \"anglez_diffabs\"]:\n",
    "        \n",
    "        for n in [21, 61]:\n",
    "            df[f'{col}_diff_{n}'] = df[col].diff(periods=n).astype(np.float32)\n",
    "        \n",
    "            rol_args = {'window':f'{n*5}s', 'min_periods':1, 'center':True}\n",
    "            \n",
    "            for agg in ['median', 'mean', 'max', 'min', 'std']:\n",
    "                df[f'{col}_{agg}_{n}'] = df[col].rolling(**rol_args).agg(agg).astype(np.float32).values\n",
    "                gc.collect()\n",
    "            \n",
    "            df[f'{col}_mad_{n}'] = (df[col] - df[f'{col}_median_{n}']).abs().rolling(**rol_args).median().astype(np.float32)\n",
    "\n",
    "            df[f'{col}_amplit_{n}'] = df[f'{col}_max_{n}']-df[f'{col}_min_{n}']\n",
    "            df[f'{col}_diff_{n}_max'] = df[f'{col}_max_{n}'].rolling(**rol_args).max().astype(np.float32)\n",
    "            df[f'{col}_medianxstd_{n}'] = df[f'{col}_median_{n}'] * df[f'{col}_std_{n}']\n",
    "    \n",
    "            gc.collect()\n",
    "        \n",
    "#         df[f'conv1d_{col}']\n",
    "\n",
    "    df.drop(columns=['anglez_x_enmo', 'anglez_diffabs', 'anglez_diff', 'anglez',], inplace = True)\n",
    "    \n",
    "    df.drop(columns=[\n",
    "        'anglez_x_enmo_diff_21', 'anglez_std_21', 'anglezabs_std_21', 'anglezabs_mad_21', \n",
    "        'anglezabs_amplit_21', 'anglez_diff_21', 'anglez_x_enmo_std_21', 'anglez_diff_median_21', \n",
    "        'anglez_diff_mean_21', 'anglez_diff_diff_21', 'anglez_x_enmo_mean_21', 'anglez_diff_amplit_21',\n",
    "        'anglez_diff_medianxstd_21', 'enmo_diff_21', 'anglez_diffabs_diff_21',\n",
    "        'anglez_diff_max_21', 'anglez_diffabs_max_21', 'anglez_diffabs_amplit_21'\n",
    "    ], inplace = True)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    df.ffill(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df = reduce_mem_usage(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train_multi.parquet'\n",
    "\n",
    "def feat_eng_by_id(idx):\n",
    "    \n",
    "    df  = pd.read_parquet(file, filters=[('series_id','=',idx)])\n",
    "    df['awake'] = df['awake'].astype(np.int8)\n",
    "    df = feat_eng(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_id  = pd.read_parquet(file, columns=['series_id'])\n",
    "series_id = series_id.series_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = Parallel(n_jobs=6)(delayed(feat_eng_by_id)(i) for i in series_id)\n",
    "train = pd.concat(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['series_id', 'step', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['awake'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy = {0: 4500020 , 1: 5000000, 2:3120000  }\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=sampling_strategy)\n",
    "X, y = rus.fit_resample(train.drop(columns=drop_cols+['awake']), train['awake'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {    \n",
    "    'boosting_type':'gbdt',\n",
    "    'num_leaves':31,\n",
    "    'max_depth':4,\n",
    "    'learning_rate':0.03,\n",
    "    'n_estimators':150,\n",
    "    'subsample_for_bin':200000,\n",
    "    'min_child_weight':0.001,\n",
    "    'min_child_samples':20,\n",
    "    'subsample':0.6,\n",
    "    'colsample_bytree':0.7,\n",
    "    'reg_alpha':0.05,\n",
    "    'reg_lambda':0.05,\n",
    "    'random_state':666\n",
    "             }\n",
    "\n",
    "\n",
    "m = lgb.LGBMClassifier(**lgb_params)\n",
    "m.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(m.feature_importances_, index=X.columns).sort_values()\n",
    "fig = px.bar(x=feat_imp, y=feat_imp.index, orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp[feat_imp==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(idx):\n",
    "    \n",
    "    test  = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet',\n",
    "                            filters=[('series_id','=',idx)])\n",
    "    test = feat_eng(test)\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    p = m.predict_proba(X_test)\n",
    "    \n",
    "    test[\"not_awake\"] = p[:,0]\n",
    "    test[\"awake\"]     = p[:,1]\n",
    "    \n",
    "    smoothing_length = 2*230\n",
    "\n",
    "    test[\"score\"]  = test[\"awake\"].rolling(smoothing_length, center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    test[\"smooth\"] = test[\"not_awake\"].rolling(smoothing_length, center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    # re-binarize\n",
    "    test[\"smooth\"] = test[\"smooth\"].round()\n",
    "\n",
    "    # https://stackoverflow.com/questions/73777727/how-to-mark-start-end-of-a-series-of-non-null-and-non-0-values-in-a-column-of-a\n",
    "    def get_event(df):\n",
    "        lstCV = zip(df.series_id, df.smooth)\n",
    "        lstPOI = []\n",
    "        for (c, v), g in groupby(lstCV, lambda cv: \n",
    "                                (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n",
    "            llg = sum(1 for item in g)\n",
    "            if v is False: \n",
    "                lstPOI.extend([0]*llg)\n",
    "            else: \n",
    "                lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n",
    "        return lstPOI\n",
    "\n",
    "    test['event'] = get_event(test)\n",
    "    \n",
    "    return test.loc[test['event'] != 0][['series_id','step','event','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_id  = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet', columns=['series_id'])\n",
    "series_id = series_id.series_id.unique()\n",
    "tests = []\n",
    "\n",
    "for idx in series_id:\n",
    "    tests.append(predict_test(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = test.copy().reset_index(drop=True).reset_index(names='row_id')\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
