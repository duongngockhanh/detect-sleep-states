{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from itertools import combinations\n",
    "from itertools import groupby\n",
    "\n",
    "# Import sklearn classes for model selection, cross validation, and performance evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Import libraries for Hypertuning\n",
    "import optuna\n",
    "\n",
    "#Import libraries for gradient boosting\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import Pool\n",
    "\n",
    "\n",
    "\n",
    "# Useful line of code to set the display option so we could see all the columns in pd dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet\")\n",
    "test  = pd.read_parquet(\"/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\")\n",
    "\n",
    "# parse the timestamp and create an \"hour\" feature\n",
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"],utc=True)\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "\n",
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"],utc=True)\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/carlmcbrideellis/zzzs-random-forest-model-starter\n",
    "def create_features(df):\n",
    "    # parse the timestamp and create an \"hour\" feature\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],utc=True)\n",
    "    df[\"hour\"] = (df[\"timestamp\"].dt.hour).astype('int8')\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "\n",
    "    # Calculate the half-hour periods\n",
    "    df['half_hour'] = (df['hour'] * 2 + (df['minute'] // 30)).astype('int8')\n",
    "    \n",
    "    df.drop(columns=['minute'], inplace=True)\n",
    "    \n",
    "    # feature cross\n",
    "    df[\"anglez_times_enmo\"] = abs(df[\"anglez\"]) * df[\"enmo\"].astype('float16')\n",
    "    # \"rolling\" features\n",
    "    periods = 50\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"enmo_diff\"]   = df.groupby('series_id')['enmo'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"anglez_rolling\"] = df[\"anglez\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling\"]   = df[\"enmo\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling\"] = df[\"anglez_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling\"]   = df[\"enmo_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    \n",
    "    return df\n",
    "\n",
    "features = [\"hour\",\"anglez_times_enmo\", \"half_hour\",\n",
    "           \"anglez\",\"anglez_diff\",\"anglez_rolling\",\"anglez_diff_rolling\",\n",
    "           \"enmo\",\"enmo_diff\",\"enmo_rolling\",\"enmo_diff_rolling\"]\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[\"awake\"].astype('int8')\n",
    "X_test = test[features]\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, n_estimators=100, device=\"cpu\", random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.device = device\n",
    "        self.random_state = random_state\n",
    "        self.models = self._define_model()\n",
    "        self.models_name = list(self._define_model().keys())\n",
    "        self.len_models = len(self.models)\n",
    "        \n",
    "    def _define_model(self):\n",
    "        \n",
    "        xgb_1 = {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'eval_metric': 'map',\n",
    "            'verbosity': 0,\n",
    "            'random_state': self.random_state,\n",
    "            'scale_pos_weight': 2/3\n",
    "        }\n",
    "        \n",
    "        lgb_opt = {\n",
    "            'num_leaves': 204,\n",
    "            'learning_rate': 0.07649523437092402,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        if self.device == 'gpu':\n",
    "            xgb_params['tree_method'] = 'gpu_hist'\n",
    "            xgb_params['predictor'] = 'gpu_predictor'\n",
    "       \n",
    "        models = {\n",
    "            #'xgb_1': xgb.XGBClassifier(**xgb_1),\n",
    "            'lgb_opt': lgb.LGBMClassifier(**lgb_opt),\n",
    "            'rf': RandomForestClassifier(max_depth=4, min_samples_leaf=100, n_estimators=50, random_state=self.random_state),\n",
    "            #'lr': LogisticRegression(max_iter=150, random_state=self.random_state, n_jobs=-1),\n",
    "        }\n",
    "        \n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "random_state = 42\n",
    "random_state_list =[42]\n",
    "n_estimators = 90\n",
    "device = 'cpu'\n",
    "early_stopping_rounds = 50\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# Initialize an array for storing test predictions\n",
    "classifier = Classifier(n_estimators=n_estimators, device=device, random_state=random_state)\n",
    "test_predss = np.zeros((X_test.shape[0]))\n",
    "oof_predss = np.zeros((X_train.shape[0]))\n",
    "\n",
    "del X_train\n",
    "\n",
    "models_name = [_ for _ in classifier.models_name if ('xgb' in _) or ('lgb' in _) or ('cat' in _)]\n",
    "score_dict = dict(zip(classifier.models_name, [[] for _ in range(len(classifier.models_name))]))\n",
    "\n",
    "models = classifier.models\n",
    "\n",
    "# Store oof and test predictions for each base model\n",
    "oof_preds = []\n",
    "test_preds = []\n",
    "\n",
    "# Loop over each base model and fit it\n",
    "for name, model in models.items():\n",
    "    if name in ['xgb', 'lgb', 'cat', 'lgb2']:\n",
    "        model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n",
    "    else:\n",
    "        model.fit(X_train_, y_train_)\n",
    "\n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    score = average_precision_score(y_val, y_val_pred)\n",
    "    score_dict[name].append(score)\n",
    "        \n",
    "    print(f'{name} [SEED-{random_state}] Precision score: {score:.5f}')\n",
    "        \n",
    "    oof_preds.append(y_val_pred)\n",
    "    test_preds.append(test_pred)\n",
    "    \n",
    "test_predss = np.average(np.array(test_preds), axis=0)\n",
    "oof_predss[X_val.index] = np.average(np.array(oof_preds), axis=0)\n",
    "    \n",
    "gc.collect()\n",
    "del X_train_, X_val, y_val, y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_palette = sns.cubehelix_palette(n_colors = 7, start=.46, rot=-.45, dark = .2, hue=0.95, as_cmap=True)\n",
    "\n",
    "def show_confusion_roc(oof, title='Model Evaluation Results'):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    df = pd.DataFrame({'preds': oof[0], 'target': oof[1]})\n",
    "    cm = confusion_matrix(df.target, df.preds.ge(0.5).astype(int))\n",
    "    cm_display = ConfusionMatrixDisplay(cm).plot(cmap=my_palette, ax=ax[0])\n",
    "    ax[0].grid(False)\n",
    "    RocCurveDisplay.from_predictions(df.target, df.preds, ax=ax[1])\n",
    "    ax[1].grid(True)\n",
    "    plt.suptitle(f'{title}', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "show_confusion_roc(oof=[oof_predss, y_train], title='EC1 OOF Evaluation Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"not_awake\" column as the complement of the \"score\" column:\n",
    "test['score'] = test_predss\n",
    "test[\"not_awake\"] = 1 - test[\"score\"]\n",
    "\n",
    "# Smoothing of the predictions:\n",
    "smoothing_length = 400  # Define the length for smoothing\n",
    "test[\"smooth\"] = test[\"not_awake\"].rolling(smoothing_length, center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "\n",
    "# Re-binarize the \"smooth\" column:\n",
    "test[\"smooth\"] = test[\"smooth\"].round()\n",
    "\n",
    "# https://stackoverflow.com/questions/73777727/how-to-mark-start-end-of-a-series-of-non-null-and-non-0-values-in-a-column-of-a\n",
    "def get_event(df):\n",
    "    lstCV = zip(df.series_id, df.smooth)\n",
    "    lstPOI = []\n",
    "    for (c, v), g in groupby(lstCV, lambda cv: \n",
    "                            (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n",
    "        llg = sum(1 for item in g)\n",
    "        if v is False: \n",
    "            lstPOI.extend([0]*llg)\n",
    "        else: \n",
    "            lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n",
    "    return lstPOI\n",
    "\n",
    "test[\"event\"] = get_event(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = test.loc[test[\"event\"] != 0]\n",
    "sample_submission = sample_submission[[\"series_id\", \"step\", \"event\", \"score\"]].copy()\n",
    "sample_submission = sample_submission.reset_index(drop=True).reset_index(names=\"row_id\")\n",
    "\n",
    "# Save the sample submission DataFrame to a CSV file:\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
